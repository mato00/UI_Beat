from __future__ import annotations

import json
from pathlib import Path
from typing import Callable, Dict, List, Optional

import numpy as np
import torch
from torch import Tensor
from torch.utils.data import Dataset


class PWaveSegmentDataset(Dataset):
    """
    Dataset for 10-second ECG segments with P-wave masks generated by pwave_preprocess.

    Each item is stored as a JSON file containing the filtered ECG samples (200 Hz),
    a downsampled label mask (50 Hz, 500 samples per segment), and metadata used to
    reconstruct the record identity.
    """

    def __init__(
        self,
        root: Path | str,
        split: Optional[str] = None,
        transform: Optional[Callable[[Tensor], Tensor]] = None,
        target_transform: Optional[Callable[[Tensor], Tensor]] = None,
    ) -> None:
        """
        Args:
            root: Path to the dataset root. Can be either the split directory
                (e.g. ".../p_wave_dataset/train") or the parent directory.
            split: Optional split name ("train", "val", "test"). If provided,
                data will be loaded from ``root / split``.
            transform: Callable applied to the ECG signal tensor.
            target_transform: Callable applied to the mask tensor.
        """

        root_path = Path(root)
        if split:
            root_path = root_path / split

        if not root_path.exists():
            raise FileNotFoundError(f"Dataset path not found: {root_path}")
        if not root_path.is_dir():
            raise NotADirectoryError(f"Dataset path must be a directory: {root_path}")

        self.root = root_path
        self.transform = transform
        self.target_transform = target_transform
        self.records: List[Path] = sorted(self.root.rglob("*.json"))

        if not self.records:
            raise RuntimeError(f"No segment files found under {self.root}")

    def __len__(self) -> int:
        return len(self.records)

    def _load_segment(self, path: Path) -> Dict[str, np.ndarray | str | int]:
        with path.open("r", encoding="utf-8") as fp:
            payload = json.load(fp)

        if "ecg" not in payload or "label" not in payload:
            raise KeyError(f"Missing 'ecg' or 'label' key in {path}")

        signal = np.asarray(payload["ecg"], dtype=np.float32)
        mask = np.asarray(payload["label"], dtype=np.float32)

        # Ensure channel-first format with a single lead dimension.
        if signal.ndim == 1:
            signal = signal[np.newaxis, :]
        elif signal.ndim == 2 and signal.shape[0] < signal.shape[1]:
            # Stored as samples x leads -> convert to leads x samples.
            signal = signal.T
        elif signal.ndim != 2:
            raise ValueError(f"Unexpected ECG array shape in {path}: {signal.shape}")

        record_id = payload.get("record_id")
        if not record_id:
            relative = path.relative_to(self.root)
            record_id = relative.with_suffix("").as_posix()

        segment = {
            "signal": signal,
            "mask": mask,
            "record_index": payload.get("record_index"),
            "segment_index": payload.get("segment_index"),
            "lead": payload.get("lead"),
            "record_id": record_id,
        }
        return segment

    def __getitem__(self, index: int) -> Dict[str, Tensor | str | int | None]:
        segment = self._load_segment(self.records[index])
        signal_tensor = torch.from_numpy(segment["signal"])
        mask_tensor = torch.from_numpy(segment["mask"])

        if self.transform is not None:
            signal_tensor = self.transform(signal_tensor)
        if self.target_transform is not None:
            mask_tensor = self.target_transform(mask_tensor)

        return {
            "signal": signal_tensor,
            "mask": mask_tensor,
            "record_id": segment["record_id"],
            "record_index": segment["record_index"],
            "segment_index": segment["segment_index"],
            "lead": segment["lead"],
        }


def pwave_collate_fn(batch: List[Dict[str, Tensor | str | int | None]]) -> tuple[Tensor, Tensor, List[str]]:
    signals = torch.stack([item["signal"] for item in batch])
    masks = torch.stack([item["mask"] for item in batch])
    record_ids = [str(item["record_id"]) for item in batch]
    return signals, masks, record_ids


__all__ = ["PWaveSegmentDataset", "pwave_collate_fn"]


if __name__ == "__main__":
    dataset_root = Path(__file__).resolve().parents[1] / "data" / "p_wave_dataset"

    dataset = PWaveSegmentDataset(root=dataset_root, split="train")
    print(f"Total segments: {len(dataset)}")

    sample = dataset[0]
    signal_tensor: Tensor = sample["signal"]
    mask_tensor: Tensor = sample["mask"]

    print(f"Record ID: {sample['record_id']}")
    print(f"Signal shape: {tuple(signal_tensor.shape)}")
    print(f"Mask shape: {tuple(mask_tensor.shape)}")
    print(f"Mask positives: {(mask_tensor > 0).sum().item()}")
